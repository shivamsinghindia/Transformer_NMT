{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa0c116-9059-406d-adf5-59777f1908b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets.translation import IWSLT\n",
    "import spacy\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "import sys\n",
    "from torchtext.data import Field, BucketIterator\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torchtext.datasets.translation import Multi30k\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eebe8c8-9f5d-4df2-9465-5688cadd09e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    return {\n",
    "        \"batch_size\": 32,\n",
    "        \"num_epochs\": 20,\n",
    "        \"lr\": 10**-4,\n",
    "        \"seq_len\": 20,\n",
    "        \"d_model\": 512,\n",
    "        \"src_lang\": \"eng\",\n",
    "        \"trg_lang\": \"fra\",\n",
    "        \"model_folder\": \"weights\",\n",
    "        \"model_basename\": \"tmodel_\",\n",
    "        \"preload\": None,\n",
    "        \"tokenizer_file\": \"tokenizer_{0}.json\",\n",
    "        \"experiment_name\": \"runs/tmodel\"\n",
    "    }\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1f57d-dc2b-42c5-b577-73c8d62a54d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b3d73ac-4598-4841-988b-90d24604c9b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.heads = heads\n",
    "        self.head_dim = d_model // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == d_model\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.keys = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.queries = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.fc_out = nn.Linear(self.d_model, self.d_model,bias=False)\n",
    "\n",
    "    # values == keys == query == [batch_size,seq_len,d_model]\n",
    "    \n",
    "    def forward(self, values, keys, query, mask):\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "        \n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(query)\n",
    "        \n",
    "        # [batch_size,seq_len,d_model] -> [batch_size,seq_len,heads,head_dim]\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        # mat mul: energy == [batch_size,heads,seq_len,seq_len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "        \n",
    "        attention = torch.softmax(energy / (self.d_model ** (1 / 2)), dim=3)\n",
    "        #attention == [batch_size,heads,seq_len,seq_len]\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        #out == [batch_size,seq_len,d_model]\n",
    "        \n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e6240e-9804-4b8f-b112-30c77dc369b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(d_model, heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, forward_expansion * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * d_model, d_model),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        # attention = [batch_size,seq_len,d_model]\n",
    "        # query = [batch_size,seq_len,d_model]\n",
    "        attention = self.attention(value, key, query, mask) \n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        # x == [batch_size,seq_len,d_model]\n",
    "        forward = self.feed_forward(x)\n",
    "        # forward == [batch_size,seq_len,d_model]\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a38c8e-3622-49e9-8748-44de602e1a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        d_model,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    d_model,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x == [batch_size,seq_len]\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(\n",
    "            (self.word_embedding(x) + self.position_embedding(positions))\n",
    "        )\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "548dcc2d-6de0-425e-8b12-ee025d968f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.attention = SelfAttention(d_model, heads=heads)\n",
    "        self.transformer_block = TransformerBlock(\n",
    "            d_model, heads, dropout, forward_expansion\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9926561-0b96-4745-a87d-11432d849863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trg_vocab_size,\n",
    "        d_model,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        device,\n",
    "        max_length,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(max_length, d_model)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(d_model, heads, forward_expansion, dropout, device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48889448-a86f-43f4-bb53-6482367cd03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        heads=8,\n",
    "        d_model = 512,\n",
    "        num_layers=3,\n",
    "        forward_expansion=4,\n",
    "        dropout=0.1,\n",
    "        max_length=100,\n",
    "        \n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            d_model,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            d_model,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # (N, 1, 1, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        N, trg_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "            N, 1, trg_len, trg_len\n",
    "        )\n",
    "\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b0c2b42-e9e0-4683-a096-cd048802912b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = \"SOS\"\n",
    "EOS_token = \"EOS\"\n",
    "PAD_token = \"PAD\"\n",
    "UNK_token = \"UNK\"\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"SOS\": 0,\"EOS\":1,\"PAD\":2,\"UNK\":3}\n",
    "        self.word2count = {\"SOS\": 1,\"EOS\":1,\"PAD\":1,\"UNK\":1}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\",2:\"PAD\",3:\"UNK\"}\n",
    "        self.n_words = 4  # Count SOS and EOS and PAD and UNK\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d54e521-84b1-4387-a0f8-bc1a20da12bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a0e818-4a6b-4780-ad54-ff7728a3f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e9447e6-5159-4b34-9f02-31d769e4550d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    pairs = filterPairs(pairs)\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbb2f241-10d5-470d-bdb7-febbf1ea59a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self,src_lang,trg_lang,seq_len):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.token_src, self.token_trg, self.pairs = readLangs(src_lang,trg_lang,True)\n",
    "        self.sos_token = torch.tensor([self.token_src.word2index[SOS_token]],dtype=torch.int64)\n",
    "        self.eos_token = torch.tensor([self.token_src.word2index[EOS_token]],dtype=torch.int64)\n",
    "        self.pad_token = torch.tensor([self.token_src.word2index[PAD_token]],dtype=torch.int64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        src_trg_pair = self.pairs[idx]\n",
    "        src_text = src_trg_pair[0]\n",
    "        trg_text = src_trg_pair[1]\n",
    "        \n",
    "        encoder_input_tokens = [self.token_src.word2index[word] for word in src_text.split(' ')]\n",
    "        decoder_input_tokens = [self.token_trg.word2index[word] for word in trg_text.split(' ')]\n",
    "        \n",
    "        enc_num_padding_tokens = self.seq_len - len(encoder_input_tokens) - 2\n",
    "        dec_num_padding_tokens = self.seq_len - len(decoder_input_tokens) - 1\n",
    "        \n",
    "        if enc_num_padding_tokens < 0 or dec_num_padding_tokens < 0:\n",
    "            raise ValueError(\"Sentence is too long\")\n",
    "            \n",
    "        encoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(encoder_input_tokens,dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * enc_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim = 0\n",
    "        )\n",
    "        \n",
    "        decoder_input = torch.cat(\n",
    "            [\n",
    "                self.sos_token,\n",
    "                torch.tensor(decoder_input_tokens, dtype=torch.int64),\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim = 0\n",
    "        )\n",
    "        \n",
    "        label = torch.cat(\n",
    "            [\n",
    "                torch.tensor(decoder_input_tokens, dtype=torch.int64),\n",
    "                self.eos_token,\n",
    "                torch.tensor([self.pad_token] * dec_num_padding_tokens, dtype=torch.int64),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "        \n",
    "        assert encoder_input.size(0) == self.seq_len\n",
    "        assert decoder_input.size(0) == self.seq_len\n",
    "        assert label.size(0) == self.seq_len\n",
    "        \n",
    "        return {\n",
    "            \"encoder_input\": encoder_input,  # (seq_len)\n",
    "            \"decoder_input\": decoder_input,  # (seq_len)\n",
    "            \"encoder_mask\": (encoder_input != self.pad_token).unsqueeze(1).unsqueeze(2), # (1, 1, seq_len)\n",
    "            \"decoder_mask\": (decoder_input != self.pad_token), # (1, seq_len) & (1, seq_len, seq_len),\n",
    "            \"label\": label,  # (seq_len)\n",
    "            \"src_text\": src_text,\n",
    "            \"tgt_text\": trg_text,\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1017ed7-9c42-48c9-acde-abb89db9ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(config):\n",
    "    train_ds = Data(config[\"src_lang\"],config[\"trg_lang\"],config[\"seq_len\"])\n",
    "    train_dataloader = DataLoader(train_ds,config[\"batch_size\"],shuffle = True)\n",
    "    \n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98856f7d-7bb8-4388-a7fc-781136340972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "token_src, token_trg, pairs = readLangs('eng','fra',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3245d057-6ff4-4882-adbf-460af59bebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    src_vocab_size = 17866\n",
    "    trg_vocab_size = 10700\n",
    "    model = Transformer(\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        2,\n",
    "        2,\n",
    "        device=device\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6c2584d4-28db-471a-9d4d-55108b86e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence,model):\n",
    "    sentence = normalizeString(sentence)\n",
    "    tokens = [token_src.word2index[word] for word in sentence.split(' ')]\n",
    "    tokens.append(token_src.word2index[EOS_token])\n",
    "    tokens.insert(0,token_src.word2index[SOS_token])\n",
    "    for _ in range(20-len(tokens)):\n",
    "        tokens.append(token_src.word2index[PAD_token])\n",
    "    tokens = torch.LongTensor(tokens).unsqueeze(0).to(device)\n",
    "    outputs = [token_trg.word2index[SOS_token]]\n",
    "    for i in range(20):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(tokens, trg_tensor)\n",
    "        best_guess = output.argmax(2)[:, -1].item()\n",
    "        outputs.append(best_guess)\n",
    "        # print(outputs)\n",
    "    \n",
    "        if best_guess == 1:\n",
    "            break\n",
    "    translated_sentence = [token_trg.index2word[word] for word in outputs]\n",
    "    translated_sentence = translated_sentence[1:-1]\n",
    "    final = \" \".join([str(elem) for elem in translated_sentence])\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c8c32ae7-0dd7-4caf-9a8d-35cc41c17343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], eps=1e-9)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=2, label_smoothing=0.1).to(device)\n",
    "def train():\n",
    "    train_ds = get_ds(config)\n",
    "    initial_epoch = 0\n",
    "    step = 0\n",
    "    for epoch in range(initial_epoch,config[\"num_epochs\"]):\n",
    "        torch.cuda.empty_cache()\n",
    "        model.train()\n",
    "        batch_iterator = tqdm(train_ds, desc=f\"Processing Epoch {epoch:02d}\")\n",
    "        \n",
    "        for batch in batch_iterator:\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            decoder_input = batch['decoder_input'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "            out = model(encoder_input,decoder_input)\n",
    "            loss = loss_fn(out.view(-1, 10700), label.view(-1))\n",
    "            batch_iterator.set_postfix({\"loss\": f\"{loss.item():6.3f}\"})\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        model.eval()\n",
    "        sentence=\"Comment vous appelez-vous ?\"\n",
    "        print(\"SENTENCE: \",sentence)\n",
    "        print(\"EXPECTED: \",\"can you stay a while?\")\n",
    "        print(\"PREDICTED: \",translate_sentence(sentence,model))\n",
    "        torch.save(model.state_dict(), f'models/model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e116030c-c54d-45bf-9857-7da391afe903",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "93a31652-7f12-41fc-bfa5-16214304823d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (word_embedding): Embedding(17866, 512)\n",
       "    (position_embedding): Embedding(100, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x TransformerBlock(\n",
       "        (attention): SelfAttention(\n",
       "          (values): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (keys): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (queries): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (word_embedding): Embedding(10700, 512)\n",
       "    (position_embedding): Embedding(100, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x DecoderBlock(\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): SelfAttention(\n",
       "          (values): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (keys): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (queries): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (transformer_block): TransformerBlock(\n",
       "          (attention): SelfAttention(\n",
       "            (values): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (keys): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (queries): Linear(in_features=512, out_features=512, bias=False)\n",
       "            (fc_out): Linear(in_features=512, out_features=512, bias=False)\n",
       "          )\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=512, out_features=10700, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model().to(device)\n",
    "model.load_state_dict(torch.load(\"models/model_19.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3c1aa05e-3c5e-4974-b5a0-416348a00edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'may i have the check please ? EOS'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Je peux avoir l'addition, s'il vous plaît ?\"\n",
    "translate_sentence(sentence,model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
